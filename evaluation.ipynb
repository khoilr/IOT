{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install keras_cv_attention_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evals\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import IJB_evals\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_cv_attention_models\n",
    "import GhostFaceNets, GhostFaceNets_with_Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "print(tf.config.list_physical_devices(\"GPU\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 ways to load the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stride 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Either\n",
    "basic_model = keras.models.load_model(\n",
    "    \"checkpoints/ghostnetv1_w1.3_s2.h5\", compile=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the above did not work, then you need to build the model then load the weights. e.g.,\n",
    "basic_model = GhostFaceNets_with_Bias.buildin_models(\n",
    "    \"ghostnetv1\",\n",
    "    dropout=0,\n",
    "    emb_shape=512,\n",
    "    output_layer=\"GDC\",\n",
    "    bn_momentum=0.9,\n",
    "    bn_epsilon=1e-5,\n",
    ")\n",
    "basic_model = GhostFaceNets_with_Bias.add_l2_regularizer_2_model(\n",
    "    basic_model, weight_decay=5e-4, apply_to_batch_normal=False\n",
    ")\n",
    "basic_model = GhostFaceNets_with_Bias.replace_ReLU_with_PReLU(\n",
    "    basic_model, target_activation=\"PReLU\"\n",
    ")\n",
    "\n",
    "basic_model.load_weights(\"checkpoints/ghostnetv1_w1.3_s2.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stride 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Either\n",
    "basic_model = keras.models.load_model(\"checkpoints/ghostnetv1_w1.3_s1.h5\", compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Change BatchNormalization momentum and epsilon default value.\n",
      ">>>> Convert ReLU: activation_384 --> activation_384\n",
      ">>>> Convert ReLU: activation_385 --> activation_385\n",
      ">>>> Convert ReLU: activation_386 --> activation_386\n",
      ">>>> Convert ReLU: activation_387 --> activation_387\n",
      ">>>> Convert ReLU: activation_388 --> activation_388\n",
      ">>>> Convert ReLU: activation_389 --> activation_389\n",
      ">>>> Convert ReLU: activation_390 --> activation_390\n",
      ">>>> Convert ReLU: activation_391 --> activation_391\n",
      ">>>> Convert ReLU: activation_392 --> activation_392\n",
      ">>>> Convert ReLU: activation_393 --> activation_393\n",
      ">>>> Convert ReLU: activation_395 --> activation_395\n",
      ">>>> Convert ReLU: activation_396 --> activation_396\n",
      ">>>> Convert ReLU: activation_397 --> activation_397\n",
      ">>>> Convert ReLU: activation_399 --> activation_399\n",
      ">>>> Convert ReLU: activation_400 --> activation_400\n",
      ">>>> Convert ReLU: activation_401 --> activation_401\n",
      ">>>> Convert ReLU: activation_402 --> activation_402\n",
      ">>>> Convert ReLU: activation_403 --> activation_403\n",
      ">>>> Convert ReLU: activation_404 --> activation_404\n",
      ">>>> Convert ReLU: activation_405 --> activation_405\n",
      ">>>> Convert ReLU: activation_406 --> activation_406\n",
      ">>>> Convert ReLU: activation_407 --> activation_407\n",
      ">>>> Convert ReLU: activation_408 --> activation_408\n",
      ">>>> Convert ReLU: activation_409 --> activation_409\n",
      ">>>> Convert ReLU: activation_411 --> activation_411\n",
      ">>>> Convert ReLU: activation_412 --> activation_412\n",
      ">>>> Convert ReLU: activation_413 --> activation_413\n",
      ">>>> Convert ReLU: activation_415 --> activation_415\n",
      ">>>> Convert ReLU: activation_416 --> activation_416\n",
      ">>>> Convert ReLU: activation_417 --> activation_417\n",
      ">>>> Convert ReLU: activation_419 --> activation_419\n",
      ">>>> Convert ReLU: activation_420 --> activation_420\n",
      ">>>> Convert ReLU: activation_421 --> activation_421\n",
      ">>>> Convert ReLU: activation_422 --> activation_422\n",
      ">>>> Convert ReLU: activation_423 --> activation_423\n",
      ">>>> Convert ReLU: activation_425 --> activation_425\n",
      ">>>> Convert ReLU: activation_426 --> activation_426\n",
      ">>>> Convert ReLU: activation_427 --> activation_427\n",
      ">>>> Convert ReLU: activation_428 --> activation_428\n",
      ">>>> Convert ReLU: activation_429 --> activation_429\n",
      ">>>> Convert ReLU: activation_431 --> activation_431\n",
      ">>>> Change BatchNormalization momentum and epsilon default value.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Layer count mismatch when loading weights from file. Model expected 178 layers, found 219 saved layers.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 34\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     \u001b[39m# If the above did not work, then we need to manually set the weights of the corresponding layer\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     saved_model \u001b[39m=\u001b[39m GhostFaceNets_with_Bias\u001b[39m.\u001b[39mbuildin_models(\n\u001b[1;32m     24\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mghostnetv1\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     25\u001b[0m         dropout\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m         strides\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m     33\u001b[0m     )\n\u001b[0;32m---> 34\u001b[0m     saved_model\u001b[39m.\u001b[39;49mload_weights(\u001b[39m\"\u001b[39;49m\u001b[39mmodels/GN_W1.3_S2_ArcFace_epoch48.h5\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     35\u001b[0m     \u001b[39mfor\u001b[39;00m i, layer \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(saved_model\u001b[39m.\u001b[39mlayers):\n\u001b[1;32m     36\u001b[0m         \u001b[39mif\u001b[39;00m layer\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mGDC_conv\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai/lib/python3.10/site-packages/keras/saving/legacy/hdf5_format.py:812\u001b[0m, in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, model)\u001b[0m\n\u001b[1;32m    810\u001b[0m layer_names \u001b[39m=\u001b[39m filtered_layer_names\n\u001b[1;32m    811\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(layer_names) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(filtered_layers):\n\u001b[0;32m--> 812\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    813\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLayer count mismatch when loading weights from file. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    814\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel expected \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(filtered_layers)\u001b[39m}\u001b[39;00m\u001b[39m layers, found \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    815\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(layer_names)\u001b[39m}\u001b[39;00m\u001b[39m saved layers.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m     )\n\u001b[1;32m    818\u001b[0m \u001b[39m# We batch weight value assignments in a single backend call\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[39m# which provides a speedup in TensorFlow.\u001b[39;00m\n\u001b[1;32m    820\u001b[0m weight_value_tuples \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mValueError\u001b[0m: Layer count mismatch when loading weights from file. Model expected 178 layers, found 219 saved layers."
     ]
    }
   ],
   "source": [
    "# If the above did not work, then you need to build the model then load the weights. e.g.,\n",
    "basic_model = GhostFaceNets_with_Bias.buildin_models(\n",
    "    \"ghostnetv1\",\n",
    "    dropout=0,\n",
    "    emb_shape=512,\n",
    "    output_layer=\"GDC\",\n",
    "    bn_momentum=0.9,\n",
    "    bn_epsilon=1e-5,\n",
    "    scale=True,\n",
    "    use_bias=True,\n",
    "    strides=1,\n",
    ")\n",
    "basic_model = GhostFaceNets_with_Bias.add_l2_regularizer_2_model(\n",
    "    basic_model, weight_decay=5e-4, apply_to_batch_normal=False\n",
    ")\n",
    "basic_model = GhostFaceNets_with_Bias.replace_ReLU_with_PReLU(basic_model, target_activation=\"PReLU\")\n",
    "\n",
    "basic_model.load_weights(\"checkpoints/ghostnetv1_w1.3_s1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee = evals.EvalCallback(\n",
    "    basic_model=basic_model,\n",
    "    test_bin_file=\"datasets/faces_emore/lfw.bin\",\n",
    "    batch_size=256,\n",
    "    flip=True,\n",
    "    PCA_acc=True,\n",
    ")\n",
    "ee.on_epoch_end(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee = evals.EvalCallback(\n",
    "    basic_model,\n",
    "    \"datasets/faces_emore/lfw.bin\",\n",
    "    batch_size=256,\n",
    "    flip=True,\n",
    "    PCA_acc=False,\n",
    ")\n",
    "ee.on_epoch_end(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee = evals.EvalCallback(\n",
    "    basic_model,\n",
    "    \"datasets/faces_emore/vgg2_fp.bin\",\n",
    "    batch_size=256,\n",
    "    flip=True,\n",
    "    PCA_acc=False,\n",
    ")\n",
    "ee.on_epoch_end(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee = evals.EvalCallback(\n",
    "    basic_model,\n",
    "    \"datasets/faces_emore/cfp_ff.bin\",\n",
    "    batch_size=256,\n",
    "    flip=True,\n",
    "    PCA_acc=False,\n",
    ")\n",
    "ee.on_epoch_end(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee = evals.EvalCallback(\n",
    "    basic_model,\n",
    "    \"datasets/faces_emore/cfp_fp.bin\",\n",
    "    batch_size=256,\n",
    "    flip=True,\n",
    "    PCA_acc=False,\n",
    ")\n",
    "ee.on_epoch_end(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee = evals.EvalCallback(\n",
    "    basic_model,\n",
    "    \"datasets/faces_emore/calfw.bin\",\n",
    "    batch_size=256,\n",
    "    flip=True,\n",
    "    PCA_acc=False,\n",
    ")\n",
    "ee.on_epoch_end(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee = evals.EvalCallback(\n",
    "    basic_model,\n",
    "    \"datasets/faces_emore/cplfw.bin\",\n",
    "    batch_size=256,\n",
    "    flip=True,\n",
    "    PCA_acc=False,\n",
    ")\n",
    "ee.on_epoch_end(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee = evals.EvalCallback(\n",
    "    basic_model,\n",
    "    \"datasets/faces_emore/agedb_30.bin\",\n",
    "    batch_size=256,\n",
    "    flip=True,\n",
    "    PCA_acc=False,\n",
    ")\n",
    "ee.on_epoch_end(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = IJB_evals.IJB_test(\n",
    "    lambda imgs: basic_model((tf.cast(imgs, \"float32\") - 127.5) * 0.0078125).numpy(),\n",
    "    data_path=\"path_to_IJB_Dataset/ijb-testsuite/ijb\",\n",
    "    subset=\"IJBB\",\n",
    "    batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = tt.run_model_test_single()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IJB_evals.plot_roc_and_calculate_tpr(\n",
    "    [score], names=[basic_model.name + \"_IJBB\"], label=tt.label\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = IJB_evals.IJB_test(\n",
    "    lambda imgs: basic_model((tf.cast(imgs, \"float32\") - 127.5) * 0.0078125).numpy(),\n",
    "    data_path=\"C:/Users/mohda/Downloads/ijb-testsuite/ijb\",\n",
    "    subset=\"IJBC\",\n",
    "    batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = tt.run_model_test_single()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IJB_evals.plot_roc_and_calculate_tpr(\n",
    "    [score], names=[basic_model.name + \"_IJBC\"], label=tt.label\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot face quality distribution using norm value of feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = tf.norm(ee.embs, axis=1).numpy()\n",
    "_ = plt.hist(cc, bins=512, alpha=0.5, label=\"agedb_30 quality\")\n",
    "cc = tf.norm(tt.embs, axis=1).numpy()\n",
    "_ = plt.hist(cc, bins=512, alpha=0.5, label=\"IJBC quality\")\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
